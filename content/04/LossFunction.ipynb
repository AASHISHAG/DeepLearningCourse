{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyone makes mistakes. The wise are not people who never make mistakes, but those who forgive themselves and learn from their mistakes. —— Ajahn Brahm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does the neural network predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you take a math test, the teacher will mark you down for the mistakes you made. Your friend ask you how's your test? You may say: well, not bad. I made two mistakes and deducted 6 points. Then you learn from your mistakes and perform better the next time. The score you get on a test is an indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For neural network, there is such an indicator too. Like human, the neural network make errors. We measure it by compareing the target values and actual value producted by neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we don't know the direct conversion between pounds and kilograms. We want to learn their relationship from the data through a simple neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here $x$ is input, $w$ is weight, $y$ is the network's output and $t$ is the target value of the training data.\n",
    "\n",
    "The table shows four columns of data. What we know now is the input $x$ and the target value of the training data $t$. The neural network will output the $y$ value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  input x | target t |\n",
    "| ---- | ----------------------- |\n",
    "| 1.2    | 2.65                  |\n",
    "| 3.4    | 7.50                  |\n",
    "| 2.8    | 6.17                  |\n",
    "| 7.3    | 16.09                 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we randomly set the value of $w$ to $0.8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.8\n",
    "def neural_netwok_predict(x, w):\n",
    "    y = w * x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_error(y, t):\n",
    "    return y - t\n",
    "\n",
    "def squared_error(y, t):\n",
    "    error = row_error(y, t)\n",
    "    return error**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_get_error(x, t):\n",
    "    y = neural_netwok_predict(x, w)\n",
    "    print(\"Output y: {}\".format(y))\n",
    "\n",
    "    error = squared_error(y,t)\n",
    "    print(\"Squared error e: {}\".format(error))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the output $y$, row error and squared error one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output y: 0.96\n",
      "Squared error e: 2.8560999999999996\n"
     ]
    }
   ],
   "source": [
    "x = 1.2\n",
    "t = 2.65\n",
    "predict_and_get_error(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/0-1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output y: 2.72\n",
      "Squared error e: 22.848399999999994\n"
     ]
    }
   ],
   "source": [
    "x = 3.4\n",
    "t = 7.50\n",
    "predict_and_get_error(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/0-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output y: 2.2399999999999998\n",
      "Squared error e: 15.4449\n"
     ]
    }
   ],
   "source": [
    "x = 2.8\n",
    "t = 6.17\n",
    "predict_and_get_error(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/0-3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output y: 5.84\n",
      "Squared error e: 105.0625\n"
     ]
    }
   ],
   "source": [
    "x = 7.3\n",
    "t = 16.09\n",
    "predict_and_get_error(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/0-4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function: Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get all the output y and square errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  x | t | y | e|\n",
    "| ---- | ----------------------- | ---------|---------|\n",
    "| 1.2    | 2.65                  |  0.96                |2.8561|\n",
    "| 3.4    | 7.50                  |  2.72               |22.8484|\n",
    "| 2.8    | 6.17                  |  2.24               |15.4449|\n",
    "| 7.3    | 16.09                 |  5.84              |105.0625|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By adding up the errors in each data and average them, we get the Mean Square Error(MSE) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error(errors):\n",
    "    MAE = 1/len(errors) * sum(errors)\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36.552975"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = [2.8561,  22.8484,  15.4449, 105.0625]\n",
    "mean_square_error(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the weight is 0.8, the MAE is around 36.55.\n",
    "\n",
    "**In this way, we can calculate the MSE every time we change the value of the weight. The smaller the value of MSE, the better the prediction effect of neural network.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form of mathematical expressions of MAE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$L = \\frac{1}{n}\\sum_{i=1}^{n}\\left ( y_{i} - t_{i} \\right )^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here MAE is a **loss function** (or cost function). There are many other functions can be used as loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the positive and negative errors cancel each other out. So the total error become 0 which suggest the neural network makes no mistakes. However, that's not true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_absolute_error(y, t):\n",
    "    mse = 1/len(y) * np.sum(abs(y-t))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12499999999999997\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0.6, 0.6, 0.7, 0.95])\n",
    "t = np.array([0.5, 0.7, 0.85, 0.8])\n",
    "e = mean_absolute_error(y, t)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[add image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def mean_squared_error(y, t):\n",
    "    mse = 1/len(y) * np.sum((y-t) ** 2)\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016249999999999994\n"
     ]
    }
   ],
   "source": [
    "y = np.array([0.6, 0.6, 0.7, 0.95])\n",
    "t = np.array([0.5, 0.7, 0.85, 0.8])\n",
    "e = mean_squared_error(y, t)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we use MSE as loss function more than MAE. It relates to the gradient descent we'll talk about next. MAE isn’t continuous near the minimum which makes gradient descent not work so well."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
